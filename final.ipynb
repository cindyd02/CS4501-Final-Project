{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#% matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in adult dataset: (32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df = pd.read_csv('adult.csv')\n",
    "print(\"Number of Observations in adult dataset:\", adult_df.shape)\n",
    "\n",
    "adult_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns before deleting: 15\n",
      "Number of columns after deleting: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of columns before deleting: {adult_df.shape[1]}\")\n",
    "\n",
    "del_cols = ['relationship','education.num']\n",
    "adult_df.drop(labels = del_cols,axis = 1,inplace = True)\n",
    "print(f\"Number of columns after deleting: {adult_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people working for 99 hours per week: 85\n"
     ]
    }
   ],
   "source": [
    "hrs_per_week = adult_df[adult_df['hours.per.week'] == 99]\n",
    "print(\"Number of people working for 99 hours per week:\", hrs_per_week.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 13)\n",
      "Number of observation after removing: (32518, 13)\n"
     ]
    }
   ],
   "source": [
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df.shape)\n",
    "index_age = adult_df[adult_df['age'] == 90].index\n",
    "adult_df.drop(labels = index_age,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32518, 13)\n",
      "Number of observation after removing: (32359, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observation before removing:\",adult_df.shape)\n",
    "index_gain = adult_df[adult_df['capital.gain'] == 99999].index\n",
    "adult_df.drop(labels = index_gain,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_new = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>fnlwgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.081896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.118021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895317</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.086982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  capital.gain  capital.loss  hours.per.week    fnlwgt\n",
       "0  0.915493           0.0      1.000000        0.173469  0.081896\n",
       "1  0.690141           0.0      1.000000        0.397959  0.118021\n",
       "2  0.521127           0.0      0.895317        0.397959  0.086982"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "pd.DataFrame(scaler.fit_transform(adult_df[num_col_new]),columns = num_col_new).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('selector',DataFrameSelector(num_col_new)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32359, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = pipeline.fit_transform(adult_df)\n",
    "num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32359, 92)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.get_dummies(X)\n",
    "        df_new = df[df.columns.difference(cols)]\n",
    "#difference returns the original columns, with the columns passed as argument removed.\n",
    "        return df_new\n",
    "\n",
    "pipeline_cat=Pipeline([('selector',DataFrameSelector(cat_col_new)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df = pipeline_cat.fit_transform(adult_df)\n",
    "cat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in final dataset: (32157, 98)\n"
     ]
    }
   ],
   "source": [
    "cat_df['id'] = pd.Series(range(cat_df.shape[0]))\n",
    "num_df['id'] = pd.Series(range(num_df.shape[0]))\n",
    "final_df = pd.merge(cat_df,num_df,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_df['income_<=50K']\n",
    "final_df.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 84.3781%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1061  828]\n",
      " [ 428 5723]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 84.3781%\n",
      "Recall Score: 93.0418%\n",
      "Specificity Score: 56.1673%\n",
      "False Positive Rate: 43.8327%\n",
      "Precision Score: 87.3607%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.56      0.63      1889\n",
      "        True       0.87      0.93      0.90      6151\n",
      "\n",
      "    accuracy                           0.84      8040\n",
      "   macro avg       0.79      0.75      0.76      8040\n",
      "weighted avg       0.84      0.84      0.84      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2512564111.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 80.4851%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1102  787]\n",
      " [ 782 5369]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 80.4851%\n",
      "Recall Score: 87.2866%\n",
      "Specificity Score: 58.3377%\n",
      "False Positive Rate: 41.6623%\n",
      "Precision Score: 87.2157%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.58      0.58      1889\n",
      "        True       0.87      0.87      0.87      6151\n",
      "\n",
      "    accuracy                           0.80      8040\n",
      "   macro avg       0.73      0.73      0.73      8040\n",
      "weighted avg       0.80      0.80      0.80      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2512564111.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 81.5920%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 966  923]\n",
      " [ 557 5594]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 81.5920%\n",
      "Recall Score: 90.9446%\n",
      "Specificity Score: 51.1382%\n",
      "False Positive Rate: 48.8618%\n",
      "Precision Score: 85.8370%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.51      0.57      1889\n",
      "        True       0.86      0.91      0.88      6151\n",
      "\n",
      "    accuracy                           0.82      8040\n",
      "   macro avg       0.75      0.71      0.72      8040\n",
      "weighted avg       0.81      0.82      0.81      8040\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 36.9154%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1830   59]\n",
      " [5013 1138]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 36.9154%\n",
      "Recall Score: 18.5011%\n",
      "Specificity Score: 96.8767%\n",
      "False Positive Rate: 3.1233%\n",
      "Precision Score: 95.0710%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.27      0.97      0.42      1889\n",
      "        True       0.95      0.19      0.31      6151\n",
      "\n",
      "    accuracy                           0.37      8040\n",
      "   macro avg       0.61      0.58      0.36      8040\n",
      "weighted avg       0.79      0.37      0.34      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2512564111.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2512564111.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data - Gaussian Noise: Normal Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in adult dataset: (32359, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.737991</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-4.938454</td>\n",
       "      <td>4356</td>\n",
       "      <td>42.665837</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.550235</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-851.525204</td>\n",
       "      <td>4356</td>\n",
       "      <td>21.807815</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.160518</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>-155.126724</td>\n",
       "      <td>4356</td>\n",
       "      <td>40.866870</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.714592</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>1022.379164</td>\n",
       "      <td>3900</td>\n",
       "      <td>37.380598</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.692263</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>974.496122</td>\n",
       "      <td>3900</td>\n",
       "      <td>39.858103</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0  89.737991         ?   77053       HS-grad              9        Widowed   \n",
       "1  83.550235   Private  132870       HS-grad              9        Widowed   \n",
       "2  64.160518         ?  186061  Some-college             10        Widowed   \n",
       "3  54.714592   Private  140359       7th-8th              4       Divorced   \n",
       "4  12.692263   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female     -4.938454   \n",
       "1    Exec-managerial  Not-in-family  White  Female   -851.525204   \n",
       "2                  ?      Unmarried  Black  Female   -155.126724   \n",
       "3  Machine-op-inspct      Unmarried  White  Female   1022.379164   \n",
       "4     Prof-specialty      Own-child  White  Female    974.496122   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356       42.665837  United-States  <=50K  \n",
       "1          4356       21.807815  United-States  <=50K  \n",
       "2          4356       40.866870  United-States  <=50K  \n",
       "3          3900       37.380598  United-States  <=50K  \n",
       "4          3900       39.858103  United-States  <=50K  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "adult_df_gaussian = pd.read_csv('adult.csv')\n",
    "print(\"Number of Observations in adult dataset:\", adult_df.shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'age' column\n",
    "adult_df_gaussian['age'] += np.random.normal(loc=0, scale=10, size=adult_df_gaussian['age'].shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'capital_gain' column\n",
    "adult_df_gaussian['capital.gain'] += np.random.normal(loc=0, scale=1000, size=adult_df_gaussian['capital.gain'].shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'hours_per_week' column\n",
    "adult_df_gaussian['hours.per.week'] += np.random.normal(loc=0, scale=4, size=adult_df_gaussian['hours.per.week'].shape)\n",
    "\n",
    "adult_df_gaussian.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ML Algorithms - Gaussian Noise Normal Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 13)\n",
      "Number of observation after removing: (32561, 13)\n",
      "Number of observation before removing: (32561, 13)\n",
      "Number of observation after removing: (32561, 13)\n",
      "Number of observations in final dataset: (32561, 98)\n"
     ]
    }
   ],
   "source": [
    "# Delete columns\n",
    "del_cols_gaussian = ['relationship','education.num']\n",
    "adult_df_gaussian.drop(labels = del_cols,axis = 1,inplace = True)\n",
    "\n",
    "hrs_per_week_gaussian = adult_df_gaussian[adult_df_gaussian['hours.per.week'] == 99]\n",
    "\n",
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df_gaussian.shape)\n",
    "index_age_gaussian = adult_df_gaussian[adult_df_gaussian['age'] == 90].index\n",
    "adult_df_gaussian.drop(labels = index_age_gaussian,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_gaussian.shape)\n",
    "\n",
    "print(\"Number of observation before removing:\",adult_df_gaussian.shape)\n",
    "index_gain_gaussian = adult_df_gaussian[adult_df_gaussian['capital.gain'] == 99999].index\n",
    "adult_df_gaussian.drop(labels = index_gain_gaussian,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_gaussian.shape)\n",
    "\n",
    "num_col_new_gaussian = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new_gaussian = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler_gaussian = MinMaxScaler()\n",
    "pd.DataFrame(scaler_gaussian.fit_transform(adult_df_gaussian[num_col_new_gaussian]),columns = num_col_new_gaussian).head(3)\n",
    "\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline_gaussian = Pipeline([('selector',DataFrameSelector(num_col_new)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n",
    "num_df_gaussian = pipeline_gaussian.fit_transform(adult_df_gaussian)\n",
    "num_df_gaussian.shape\n",
    "\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols_gaussian = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']\n",
    "\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols_gaussian\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df_gaussian = pd.get_dummies(X)\n",
    "        df_new_gaussian = df_gaussian[df_gaussian.columns.difference(cols)]\n",
    "#difference returns the original columns, with the columns passed as argument removed.\n",
    "        return df_new_gaussian\n",
    "\n",
    "pipeline_cat_gaussian=Pipeline([('selector',DataFrameSelector(cat_col_new)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df_gaussian = pipeline_cat_gaussian.fit_transform(adult_df_gaussian)\n",
    "cat_df_gaussian.shape\n",
    "\n",
    "cat_df_gaussian['id'] = pd.Series(range(cat_df_gaussian.shape[0]))\n",
    "num_df_gaussian['id'] = pd.Series(range(num_df_gaussian.shape[0]))\n",
    "\n",
    "final_df_gaussian = pd.merge(cat_df_gaussian,num_df_gaussian,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df_gaussian.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the model - Gaussian Noise Normal Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 84.1666%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1080  864]\n",
      " [ 425 5772]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 84.1666%\n",
      "Recall Score: 93.1418%\n",
      "Specificity Score: 55.5556%\n",
      "False Positive Rate: 44.4444%\n",
      "Precision Score: 86.9801%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.56      0.63      1944\n",
      "        True       0.87      0.93      0.90      6197\n",
      "\n",
      "    accuracy                           0.84      8141\n",
      "   macro avg       0.79      0.74      0.76      8141\n",
      "weighted avg       0.83      0.84      0.83      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/1999007911.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 79.8551%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1146  798]\n",
      " [ 842 5355]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 79.8551%\n",
      "Recall Score: 86.4128%\n",
      "Specificity Score: 58.9506%\n",
      "False Positive Rate: 41.0494%\n",
      "Precision Score: 87.0307%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.59      0.58      1944\n",
      "        True       0.87      0.86      0.87      6197\n",
      "\n",
      "    accuracy                           0.80      8141\n",
      "   macro avg       0.72      0.73      0.73      8141\n",
      "weighted avg       0.80      0.80      0.80      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/1999007911.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 81.0834%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1016  928]\n",
      " [ 612 5585]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 81.0834%\n",
      "Recall Score: 90.1243%\n",
      "Specificity Score: 52.2634%\n",
      "False Positive Rate: 47.7366%\n",
      "Precision Score: 85.7516%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.52      0.57      1944\n",
      "        True       0.86      0.90      0.88      6197\n",
      "\n",
      "    accuracy                           0.81      8141\n",
      "   macro avg       0.74      0.71      0.72      8141\n",
      "weighted avg       0.80      0.81      0.80      8141\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 35.0571%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1873   71]\n",
      " [5216  981]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 35.0571%\n",
      "Recall Score: 15.8302%\n",
      "Specificity Score: 96.3477%\n",
      "False Positive Rate: 3.6523%\n",
      "Precision Score: 93.2510%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.26      0.96      0.41      1944\n",
      "        True       0.93      0.16      0.27      6197\n",
      "\n",
      "    accuracy                           0.35      8141\n",
      "   macro avg       0.60      0.56      0.34      8141\n",
      "weighted avg       0.77      0.35      0.31      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/1999007911.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/1999007911.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "y = final_df_gaussian['income_<=50K']\n",
    "final_df_gaussian.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df_gaussian\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidentification: Normal noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-identification Rate: 0.39%\n",
      "\n",
      "Distance Statistics:\n",
      "Mean Distance: 0.1254\n",
      "Median Distance: 0.1027\n",
      "Min Distance: 0.0025\n",
      "Max Distance: 1.6605\n",
      "\n",
      "Correct Matches: 126\n",
      "Total Records: 32561\n",
      "Re-identification Rate: 0.39%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "adult_df_original = pd.read_csv('adult.csv')\n",
    "\n",
    "adult_df_normal_noise = adult_df_original.copy()\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "adult_df_normal_noise['age'] += np.random.normal(loc=0, scale=10, size=adult_df_normal_noise['age'].shape)\n",
    "adult_df_normal_noise['capital.gain'] += np.random.normal(loc=0, scale=1000, size=adult_df_normal_noise['capital.gain'].shape)\n",
    "adult_df_normal_noise['hours.per.week'] += np.random.normal(loc=0, scale=4, size=adult_df_normal_noise['hours.per.week'].shape)\n",
    "\n",
    "cols_to_compare = ['age', 'capital.gain', 'hours.per.week']\n",
    "\n",
    "def normalize(df, cols):\n",
    "    return (df[cols] - df[cols].mean()) / df[cols].std()\n",
    "\n",
    "original_normalized = normalize(adult_df_original, cols_to_compare)\n",
    "normal_noise_normalized = normalize(adult_df_normal_noise, cols_to_compare)\n",
    "\n",
    "indices, distances = pairwise_distances_argmin_min(normal_noise_normalized, original_normalized)\n",
    "\n",
    "correct_matches = sum(np.arange(len(adult_df_original)) == indices)\n",
    "reidentification_rate = correct_matches / len(adult_df_original)\n",
    "\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original_Index': np.arange(len(adult_df_original)),\n",
    "    'Matched_Index': indices,\n",
    "    'Distance': distances,\n",
    "    'Correctly_Matched': np.arange(len(adult_df_original)) == indices\n",
    "})\n",
    "\n",
    "print(\"\\nDistance Statistics:\")\n",
    "print(f\"Mean Distance: {np.mean(distances):.4f}\")\n",
    "print(f\"Median Distance: {np.median(distances):.4f}\")\n",
    "print(f\"Min Distance: {np.min(distances):.4f}\")\n",
    "print(f\"Max Distance: {np.max(distances):.4f}\")\n",
    "\n",
    "print(\"\\nCorrect Matches:\", correct_matches)\n",
    "print(\"Total Records:\", len(adult_df_original))\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data - Gaussian Noise: Scale Doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in adult dataset: (32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.173122</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>865.542146</td>\n",
       "      <td>4356</td>\n",
       "      <td>35.074889</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.565386</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-1963.501084</td>\n",
       "      <td>4356</td>\n",
       "      <td>9.481541</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.912930</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>-512.760016</td>\n",
       "      <td>4356</td>\n",
       "      <td>39.373534</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.142174</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-1788.203212</td>\n",
       "      <td>3900</td>\n",
       "      <td>37.662230</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.116003</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-107.309137</td>\n",
       "      <td>3900</td>\n",
       "      <td>38.990266</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0  64.173122         ?   77053       HS-grad              9        Widowed   \n",
       "1  81.565386   Private  132870       HS-grad              9        Widowed   \n",
       "2  65.912930         ?  186061  Some-college             10        Widowed   \n",
       "3  59.142174   Private  140359       7th-8th              4       Divorced   \n",
       "4  12.116003   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female    865.542146   \n",
       "1    Exec-managerial  Not-in-family  White  Female  -1963.501084   \n",
       "2                  ?      Unmarried  Black  Female   -512.760016   \n",
       "3  Machine-op-inspct      Unmarried  White  Female  -1788.203212   \n",
       "4     Prof-specialty      Own-child  White  Female   -107.309137   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356       35.074889  United-States  <=50K  \n",
       "1          4356        9.481541  United-States  <=50K  \n",
       "2          4356       39.373534  United-States  <=50K  \n",
       "3          3900       37.662230  United-States  <=50K  \n",
       "4          3900       38.990266  United-States  <=50K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "adult_df_gaussian_num_doubled = pd.read_csv('adult.csv')\n",
    "print(\"Number of Observations in adult dataset:\", adult_df_gaussian_num_doubled.shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'age' column\n",
    "adult_df_gaussian_num_doubled['age'] += np.random.normal(loc=0, scale=20, size=adult_df_gaussian_num_doubled['age'].shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'capital_gain' column\n",
    "adult_df_gaussian_num_doubled['capital.gain'] += np.random.normal(loc=0, scale=2000, size=adult_df_gaussian_num_doubled['capital.gain'].shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'hours_per_week' column\n",
    "adult_df_gaussian_num_doubled['hours.per.week'] += np.random.normal(loc=0, scale=8, size=adult_df_gaussian_num_doubled['hours.per.week'].shape)\n",
    "\n",
    "adult_df_gaussian_num_doubled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ML Algorithms - Gaussian Noise Scale Doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 15)\n",
      "Number of observation after removing: (32561, 15)\n",
      "Number of observation before removing: (32561, 15)\n",
      "Number of observation after removing: (32561, 15)\n",
      "Number of observations in final dataset: (32561, 98)\n"
     ]
    }
   ],
   "source": [
    "hrs_per_week_gaussian_num_doubled = adult_df_gaussian_num_doubled[adult_df_gaussian_num_doubled['hours.per.week'] == 99]\n",
    "\n",
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df_gaussian_num_doubled.shape)\n",
    "index_age_gaussian_num_doubled = adult_df_gaussian_num_doubled[adult_df_gaussian_num_doubled['age'] == 90].index\n",
    "adult_df_gaussian_num_doubled.drop(labels = index_age_gaussian_num_doubled,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_gaussian_num_doubled.shape)\n",
    "\n",
    "print(\"Number of observation before removing:\",adult_df_gaussian_num_doubled.shape)\n",
    "index_gain_gaussian_num_doubled = adult_df_gaussian_num_doubled[adult_df_gaussian_num_doubled['capital.gain'] == 99999].index\n",
    "adult_df_gaussian_num_doubled.drop(labels = index_gain_gaussian_num_doubled,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_gaussian_num_doubled.shape)\n",
    "\n",
    "num_col_new_gaussian_num_doubled = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new_gaussian_num_doubled = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler_gaussian_num_doubled = MinMaxScaler()\n",
    "pd.DataFrame(scaler_gaussian_num_doubled.fit_transform(adult_df_gaussian_num_doubled[num_col_new_gaussian_num_doubled]),columns = num_col_new_gaussian_num_doubled).head(3)\n",
    "\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new_gaussian_num_doubled\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline_gaussian_num_doubled = Pipeline([('selector',DataFrameSelector(num_col_new_gaussian_num_doubled)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n",
    "num_df_gaussian_num_doubled = pipeline_gaussian_num_doubled.fit_transform(adult_df_gaussian_num_doubled)\n",
    "num_df_gaussian_num_doubled.shape\n",
    "\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols_gaussian_num_doubled = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']\n",
    "\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols  # Store the passed columns to self.cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df_gaussian_num_doubled = pd.get_dummies(X)\n",
    "        # Use self.cols instead of undefined cols\n",
    "        df_new_gaussian_num_doubled = df_gaussian_num_doubled[df_gaussian_num_doubled.columns.difference(self.cols)]\n",
    "        return df_new_gaussian_num_doubled\n",
    "\n",
    "\n",
    "pipeline_cat_gaussian_num_doubled = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_col_new_gaussian_num_doubled)),  # Make sure cat_col_new_gaussian_num_doubled is defined\n",
    "    ('dummies', dummies(cols_gaussian_num_doubled))  # Pass the actual column list here\n",
    "])\n",
    "\n",
    "cat_df_gaussian_num_doubled = pipeline_cat_gaussian_num_doubled.fit_transform(adult_df_gaussian_num_doubled)\n",
    "cat_df_gaussian_num_doubled.shape\n",
    "\n",
    "cat_df_gaussian_num_doubled['id'] = pd.Series(range(cat_df_gaussian_num_doubled.shape[0]))\n",
    "num_df_gaussian_num_doubled['id'] = pd.Series(range(num_df_gaussian_num_doubled.shape[0]))\n",
    "\n",
    "final_df_gaussian_num_doubled = pd.merge(cat_df_gaussian_num_doubled,num_df_gaussian_num_doubled,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df_gaussian_num_doubled.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the model - Gaussian Noise Scale Doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 83.8226%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1052  892]\n",
      " [ 425 5772]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 83.8226%\n",
      "Recall Score: 93.1418%\n",
      "Specificity Score: 54.1152%\n",
      "False Positive Rate: 45.8848%\n",
      "Precision Score: 86.6146%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.54      0.62      1944\n",
      "        True       0.87      0.93      0.90      6197\n",
      "\n",
      "    accuracy                           0.84      8141\n",
      "   macro avg       0.79      0.74      0.76      8141\n",
      "weighted avg       0.83      0.84      0.83      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2095576094.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 79.3760%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1104  840]\n",
      " [ 839 5358]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 79.3760%\n",
      "Recall Score: 86.4612%\n",
      "Specificity Score: 56.7901%\n",
      "False Positive Rate: 43.2099%\n",
      "Precision Score: 86.4472%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.57      0.57      1944\n",
      "        True       0.86      0.86      0.86      6197\n",
      "\n",
      "    accuracy                           0.79      8141\n",
      "   macro avg       0.72      0.72      0.72      8141\n",
      "weighted avg       0.79      0.79      0.79      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2095576094.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 81.1080%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[ 995  949]\n",
      " [ 589 5608]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 81.1080%\n",
      "Recall Score: 90.4954%\n",
      "Specificity Score: 51.1831%\n",
      "False Positive Rate: 48.8169%\n",
      "Precision Score: 85.5269%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.51      0.56      1944\n",
      "        True       0.86      0.90      0.88      6197\n",
      "\n",
      "    accuracy                           0.81      8141\n",
      "   macro avg       0.74      0.71      0.72      8141\n",
      "weighted avg       0.80      0.81      0.80      8141\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 34.9097%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1873   71]\n",
      " [5228  969]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 34.9097%\n",
      "Recall Score: 15.6366%\n",
      "Specificity Score: 96.3477%\n",
      "False Positive Rate: 3.6523%\n",
      "Precision Score: 93.1731%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.26      0.96      0.41      1944\n",
      "        True       0.93      0.16      0.27      6197\n",
      "\n",
      "    accuracy                           0.35      8141\n",
      "   macro avg       0.60      0.56      0.34      8141\n",
      "weighted avg       0.77      0.35      0.30      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2095576094.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2095576094.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "y = final_df_gaussian_num_doubled['income_<=50K']\n",
    "final_df_gaussian_num_doubled.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df_gaussian_num_doubled\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidentification for Double noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-identification Rate: 0.13%\n",
      "\n",
      "Distance Statistics:\n",
      "Mean Distance: 0.1894\n",
      "Median Distance: 0.1422\n",
      "Min Distance: 0.0034\n",
      "Max Distance: 2.2652\n",
      "\n",
      "Correct Matches: 42\n",
      "Total Records: 32561\n",
      "Re-identification Rate: 0.13%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "adult_df_original = pd.read_csv('adult.csv')\n",
    "\n",
    "adult_df_double_noise = adult_df_original.copy()\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "adult_df_double_noise['age'] += np.random.normal(loc=0, scale=20, size=adult_df_double_noise['age'].shape)\n",
    "adult_df_double_noise['capital.gain'] += np.random.normal(loc=0, scale=2000, size=adult_df_double_noise['capital.gain'].shape)\n",
    "adult_df_double_noise['hours.per.week'] += np.random.normal(loc=0, scale=8, size=adult_df_double_noise['hours.per.week'].shape)\n",
    "\n",
    "cols_to_compare = ['age', 'capital.gain', 'hours.per.week']\n",
    "\n",
    "def normalize(df, cols):\n",
    "    return (df[cols] - df[cols].mean()) / df[cols].std()\n",
    "\n",
    "original_normalized = normalize(adult_df_original, cols_to_compare)\n",
    "double_noise_normalized = normalize(adult_df_double_noise, cols_to_compare)\n",
    "\n",
    "indices, distances = pairwise_distances_argmin_min(double_noise_normalized, original_normalized)\n",
    "\n",
    "correct_matches = sum(np.arange(len(adult_df_original)) == indices)\n",
    "reidentification_rate = correct_matches / len(adult_df_original)\n",
    "\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original_Index': np.arange(len(adult_df_original)),\n",
    "    'Matched_Index': indices,\n",
    "    'Distance': distances,\n",
    "    'Correctly_Matched': np.arange(len(adult_df_original)) == indices\n",
    "})\n",
    "\n",
    "print(\"\\nDistance Statistics:\")\n",
    "print(f\"Mean Distance: {np.mean(distances):.4f}\")\n",
    "print(f\"Median Distance: {np.median(distances):.4f}\")\n",
    "print(f\"Min Distance: {np.min(distances):.4f}\")\n",
    "print(f\"Max Distance: {np.max(distances):.4f}\")\n",
    "\n",
    "print(\"\\nCorrect Matches:\", correct_matches)\n",
    "print(\"Total Records:\", len(adult_df_original))\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data - Gaussian Noise: Triple Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in adult dataset: (32561, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.259684</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>1298.313219</td>\n",
       "      <td>4356</td>\n",
       "      <td>32.612334</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.348078</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-2945.251625</td>\n",
       "      <td>4356</td>\n",
       "      <td>5.222311</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.869395</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>-769.140024</td>\n",
       "      <td>4356</td>\n",
       "      <td>39.060300</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.713261</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-2682.304819</td>\n",
       "      <td>3900</td>\n",
       "      <td>36.493345</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.325995</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>-160.963705</td>\n",
       "      <td>3900</td>\n",
       "      <td>38.485399</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0  51.259684         ?   77053       HS-grad              9        Widowed   \n",
       "1  81.348078   Private  132870       HS-grad              9        Widowed   \n",
       "2  65.869395         ?  186061  Some-college             10        Widowed   \n",
       "3  61.713261   Private  140359       7th-8th              4       Divorced   \n",
       "4  -2.325995   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female   1298.313219   \n",
       "1    Exec-managerial  Not-in-family  White  Female  -2945.251625   \n",
       "2                  ?      Unmarried  Black  Female   -769.140024   \n",
       "3  Machine-op-inspct      Unmarried  White  Female  -2682.304819   \n",
       "4     Prof-specialty      Own-child  White  Female   -160.963705   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356       32.612334  United-States  <=50K  \n",
       "1          4356        5.222311  United-States  <=50K  \n",
       "2          4356       39.060300  United-States  <=50K  \n",
       "3          3900       36.493345  United-States  <=50K  \n",
       "4          3900       38.485399  United-States  <=50K  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "adult_df_gaussian_num_triple = pd.read_csv('adult.csv')\n",
    "print(\"Number of Observations in adult dataset:\", adult_df_gaussian.shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'age' column\n",
    "adult_df_gaussian_num_triple['age'] += np.random.normal(loc=0, scale=30, size=adult_df_gaussian_num_triple['age'].shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'capital_gain' column\n",
    "adult_df_gaussian_num_triple['capital.gain'] += np.random.normal(loc=0, scale=3000, size=adult_df_gaussian_num_triple['capital.gain'].shape)\n",
    "\n",
    "# Add Gaussian noise directly to the 'hours_per_week' column\n",
    "adult_df_gaussian_num_triple['hours.per.week'] += np.random.normal(loc=0, scale=12, size=adult_df_gaussian_num_triple['hours.per.week'].shape)\n",
    "\n",
    "adult_df_gaussian_num_triple.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ML Algorithms - Gaussian Noise Triple Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 15)\n",
      "Number of observation after removing: (32561, 15)\n",
      "Number of observation before removing: (32561, 15)\n",
      "Number of observation after removing: (32561, 15)\n",
      "Number of observations in final dataset: (32561, 98)\n"
     ]
    }
   ],
   "source": [
    "hrs_per_week_gaussian_num_triple = adult_df_gaussian_num_triple[adult_df_gaussian_num_triple['hours.per.week'] == 99]\n",
    "\n",
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df_gaussian_num_triple.shape)\n",
    "index_age_gaussian_num_triple = adult_df_gaussian_num_triple[adult_df_gaussian_num_triple['age'] == 90].index\n",
    "adult_df_gaussian_num_triple.drop(labels = index_age_gaussian_num_triple,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_gaussian_num_triple.shape)\n",
    "\n",
    "print(\"Number of observation before removing:\",adult_df_gaussian_num_triple.shape)\n",
    "index_gain_gaussian_num_triple = adult_df_gaussian_num_triple[adult_df_gaussian_num_triple['capital.gain'] == 99999].index\n",
    "adult_df_gaussian_num_triple.drop(labels = index_gain_gaussian_num_triple,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_gaussian_num_triple.shape)\n",
    "\n",
    "num_col_new_gaussian_num_triple = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new_gaussian_num_triple = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler_gaussian_num_triple = MinMaxScaler()\n",
    "pd.DataFrame(scaler_gaussian_num_triple.fit_transform(adult_df_gaussian_num_triple[num_col_new_gaussian_num_triple]),columns = num_col_new_gaussian_num_triple).head(3)\n",
    "\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new_gaussian_num_triple\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline_gaussian_num_triple = Pipeline([('selector',DataFrameSelector(num_col_new_gaussian_num_triple)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n",
    "num_df_gaussian_num_triple = pipeline_gaussian_num_triple.fit_transform(adult_df_gaussian_num_triple)\n",
    "num_df_gaussian_num_triple.shape\n",
    "\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols_gaussian_num_triple = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']\n",
    "\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols_gaussian_num_triple\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df_gaussian_num_triple = pd.get_dummies(X)\n",
    "        df_new_gaussian_num_triple = df_gaussian_num_triple[df_gaussian_num_triple.columns.difference(cols)]\n",
    "#difference returns the original columns, with the columns passed as argument removed.\n",
    "        return df_new_gaussian_num_triple\n",
    "\n",
    "pipeline_cat_gaussian_num_triple=Pipeline([('selector',DataFrameSelector(cat_col_new_gaussian_num_triple)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df_gaussian_num_triple = pipeline_cat_gaussian_num_triple.fit_transform(adult_df_gaussian_num_triple)\n",
    "cat_df_gaussian_num_triple.shape\n",
    "\n",
    "cat_df_gaussian_num_triple['id'] = pd.Series(range(cat_df_gaussian_num_triple.shape[0]))\n",
    "num_df_gaussian_num_triple['id'] = pd.Series(range(num_df_gaussian_num_triple.shape[0]))\n",
    "\n",
    "final_df_gaussian_num_triple = pd.merge(cat_df_gaussian_num_triple,num_df_gaussian_num_triple,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df_gaussian_num_triple.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the model - Gaussian Noise Triple Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 83.4787%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1035  909]\n",
      " [ 436 5761]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 83.4787%\n",
      "Recall Score: 92.9643%\n",
      "Specificity Score: 53.2407%\n",
      "False Positive Rate: 46.7593%\n",
      "Precision Score: 86.3718%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.53      0.61      1944\n",
      "        True       0.86      0.93      0.90      6197\n",
      "\n",
      "    accuracy                           0.83      8141\n",
      "   macro avg       0.78      0.73      0.75      8141\n",
      "weighted avg       0.83      0.83      0.83      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2653346923.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 78.8847%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1079  865]\n",
      " [ 854 5343]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 78.8847%\n",
      "Recall Score: 86.2191%\n",
      "Specificity Score: 55.5041%\n",
      "False Positive Rate: 44.4959%\n",
      "Precision Score: 86.0664%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.56      0.56      1944\n",
      "        True       0.86      0.86      0.86      6197\n",
      "\n",
      "    accuracy                           0.79      8141\n",
      "   macro avg       0.71      0.71      0.71      8141\n",
      "weighted avg       0.79      0.79      0.79      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2653346923.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 80.7640%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[ 999  945]\n",
      " [ 621 5576]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 80.7640%\n",
      "Recall Score: 89.9790%\n",
      "Specificity Score: 51.3889%\n",
      "False Positive Rate: 48.6111%\n",
      "Precision Score: 85.5084%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.51      0.56      1944\n",
      "        True       0.86      0.90      0.88      6197\n",
      "\n",
      "    accuracy                           0.81      8141\n",
      "   macro avg       0.74      0.71      0.72      8141\n",
      "weighted avg       0.80      0.81      0.80      8141\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 34.8114%\n",
      "Null Accuracy: 76.1209%\n",
      "Confusion Matrix\n",
      "[[1873   71]\n",
      " [5236  961]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 34.8114%\n",
      "Recall Score: 15.5075%\n",
      "Specificity Score: 96.3477%\n",
      "False Positive Rate: 3.6523%\n",
      "Precision Score: 93.1202%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.26      0.96      0.41      1944\n",
      "        True       0.93      0.16      0.27      6197\n",
      "\n",
      "    accuracy                           0.35      8141\n",
      "   macro avg       0.60      0.56      0.34      8141\n",
      "weighted avg       0.77      0.35      0.30      8141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2653346923.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2653346923.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "y = final_df_gaussian_num_triple['income_<=50K']\n",
    "final_df_gaussian_num_triple.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df_gaussian_num_triple\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidentication on Triple Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-identification Rate: 0.09%\n",
      "\n",
      "Distance Statistics:\n",
      "Mean Distance: 0.2398\n",
      "Median Distance: 0.1651\n",
      "Min Distance: 0.0041\n",
      "Max Distance: 2.4078\n",
      "\n",
      "Correct Matches: 30\n",
      "Total Records: 32561\n",
      "Re-identification Rate: 0.09%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "adult_df_original = pd.read_csv('adult.csv')\n",
    "\n",
    "adult_df_triple_noise = adult_df_original.copy()\n",
    "\n",
    "\n",
    "np.random.seed(42)  \n",
    "adult_df_triple_noise['age'] += np.random.normal(loc=0, scale=30, size=adult_df_triple_noise['age'].shape)\n",
    "adult_df_triple_noise['capital.gain'] += np.random.normal(loc=0, scale=3000, size=adult_df_triple_noise['capital.gain'].shape)\n",
    "adult_df_triple_noise['hours.per.week'] += np.random.normal(loc=0, scale=12, size=adult_df_triple_noise['hours.per.week'].shape)\n",
    "\n",
    "cols_to_compare = ['age', 'capital.gain', 'hours.per.week']\n",
    "\n",
    "def normalize(df, cols):\n",
    "    return (df[cols] - df[cols].mean()) / df[cols].std()\n",
    "\n",
    "original_normalized = normalize(adult_df_original, cols_to_compare)\n",
    "triple_noise_normalized = normalize(adult_df_triple_noise, cols_to_compare)\n",
    "\n",
    "indices, distances = pairwise_distances_argmin_min(triple_noise_normalized, original_normalized)\n",
    "\n",
    "correct_matches = sum(np.arange(len(adult_df_original)) == indices)\n",
    "reidentification_rate = correct_matches / len(adult_df_original)\n",
    "\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original_Index': np.arange(len(adult_df_original)),\n",
    "    'Matched_Index': indices,\n",
    "    'Distance': distances,\n",
    "    'Correctly_Matched': np.arange(len(adult_df_original)) == indices\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\nDistance Statistics:\")\n",
    "print(f\"Mean Distance: {np.mean(distances):.4f}\")\n",
    "print(f\"Median Distance: {np.median(distances):.4f}\")\n",
    "print(f\"Min Distance: {np.min(distances):.4f}\")\n",
    "print(f\"Max Distance: {np.max(distances):.4f}\")\n",
    "\n",
    "print(\"\\nCorrect Matches:\", correct_matches)\n",
    "print(\"Total Records:\", len(adult_df_original))\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data - Gaussian Noise Categorical: Normal Noise, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num     marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9            Widowed   \n",
       "1   82   Private  132870     Doctorate              9          Separated   \n",
       "2   66         ?  186061  Some-college             10            Widowed   \n",
       "3   54   Private  140359     Doctorate              4  Married-AF-spouse   \n",
       "4   41   Private  264663  Some-college             10          Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  Other  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the CSV file\n",
    "adult_df_categorical = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "# Randomly change some values in the 'education' column\n",
    "def add_categorical_noise_inplace(column, noise_level=0.1):\n",
    "    unique_values = column.unique()\n",
    "    for i in range(len(column)):\n",
    "        if random.random() < noise_level:  # Apply noise with the given probability\n",
    "            column.iat[i] = random.choice(unique_values)\n",
    "\n",
    "# Apply noise to the 'education' column\n",
    "add_categorical_noise_inplace(adult_df_categorical['education'], noise_level=0.2)\n",
    "\n",
    "# Apply noise to the 'marital_status' column\n",
    "add_categorical_noise_inplace(adult_df_categorical['marital.status'], noise_level=0.2)\n",
    "\n",
    "# Apply noise to the 'race' column\n",
    "add_categorical_noise_inplace(adult_df_categorical['race'], noise_level=0.2)\n",
    "\n",
    "adult_df_categorical.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ML Algorithms - Categorical Features Random Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 13)\n",
      "Number of observation after removing: (32518, 13)\n",
      "Number of observation before removing: (32518, 13)\n",
      "Number of observation after removing: (32359, 13)\n",
      "Number of observations in final dataset: (32157, 98)\n"
     ]
    }
   ],
   "source": [
    "# Delete columns\n",
    "del_cols_categorical = ['relationship','education.num']\n",
    "adult_df_categorical.drop(labels = del_cols,axis = 1,inplace = True)\n",
    "\n",
    "hrs_per_week_categorical = adult_df_categorical[adult_df_categorical['hours.per.week'] == 99]\n",
    "\n",
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df_categorical.shape)\n",
    "index_age_categorical = adult_df_categorical[adult_df_categorical['age'] == 90].index\n",
    "adult_df_categorical.drop(labels = index_age_categorical,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical.shape)\n",
    "\n",
    "print(\"Number of observation before removing:\",adult_df_categorical.shape)\n",
    "index_gain_categorical = adult_df_categorical[adult_df_categorical['capital.gain'] == 99999].index\n",
    "adult_df_categorical.drop(labels = index_gain_categorical,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical.shape)\n",
    "\n",
    "num_col_new_categorical = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new_categorical = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler_categorical = MinMaxScaler()\n",
    "pd.DataFrame(scaler_categorical.fit_transform(adult_df_categorical[num_col_new_categorical]),columns = num_col_new_categorical).head(3)\n",
    "\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline_categorical = Pipeline([('selector',DataFrameSelector(num_col_new)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n",
    "num_df_categorical = pipeline_categorical.fit_transform(adult_df_categorical)\n",
    "num_df_categorical.shape\n",
    "\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols_categorical = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']\n",
    "\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols_categorical\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df_categorical = pd.get_dummies(X)\n",
    "        df_new_categorical = df_categorical[df_categorical.columns.difference(cols)]\n",
    "#difference returns the original columns, with the columns passed as argument removed.\n",
    "        return df_new_categorical\n",
    "\n",
    "pipeline_cat_categorical=Pipeline([('selector',DataFrameSelector(cat_col_new)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df_categorical = pipeline_cat_categorical.fit_transform(adult_df_categorical)\n",
    "cat_df_categorical.shape\n",
    "\n",
    "cat_df_categorical['id'] = pd.Series(range(cat_df_categorical.shape[0]))\n",
    "num_df_categorical['id'] = pd.Series(range(num_df_categorical.shape[0]))\n",
    "\n",
    "final_df_categorical = pd.merge(cat_df_categorical,num_df_categorical,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df_categorical.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the Model - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 83.3333%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 957  932]\n",
      " [ 408 5743]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 83.3333%\n",
      "Recall Score: 93.3669%\n",
      "Specificity Score: 50.6617%\n",
      "False Positive Rate: 49.3383%\n",
      "Precision Score: 86.0375%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.51      0.59      1889\n",
      "        True       0.86      0.93      0.90      6151\n",
      "\n",
      "    accuracy                           0.83      8040\n",
      "   macro avg       0.78      0.72      0.74      8040\n",
      "weighted avg       0.82      0.83      0.82      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 77.8856%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1017  872]\n",
      " [ 906 5245]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 77.8856%\n",
      "Recall Score: 85.2707%\n",
      "Specificity Score: 53.8380%\n",
      "False Positive Rate: 46.1620%\n",
      "Precision Score: 85.7446%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.54      0.53      1889\n",
      "        True       0.86      0.85      0.86      6151\n",
      "\n",
      "    accuracy                           0.78      8040\n",
      "   macro avg       0.69      0.70      0.69      8040\n",
      "weighted avg       0.78      0.78      0.78      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 79.9627%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 817 1072]\n",
      " [ 539 5612]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 79.9627%\n",
      "Recall Score: 91.2372%\n",
      "Specificity Score: 43.2504%\n",
      "False Positive Rate: 56.7496%\n",
      "Precision Score: 83.9617%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.43      0.50      1889\n",
      "        True       0.84      0.91      0.87      6151\n",
      "\n",
      "    accuracy                           0.80      8040\n",
      "   macro avg       0.72      0.67      0.69      8040\n",
      "weighted avg       0.78      0.80      0.79      8040\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 30.6095%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1855   34]\n",
      " [5545  606]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 30.6095%\n",
      "Recall Score: 9.8521%\n",
      "Specificity Score: 98.2001%\n",
      "False Positive Rate: 1.7999%\n",
      "Precision Score: 94.6875%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.25      0.98      0.40      1889\n",
      "        True       0.95      0.10      0.18      6151\n",
      "\n",
      "    accuracy                           0.31      8040\n",
      "   macro avg       0.60      0.54      0.29      8040\n",
      "weighted avg       0.78      0.31      0.23      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "y = final_df_categorical['income_<=50K']\n",
    "final_df_categorical.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidentification for Categorical Noise (0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship                race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family               White  Female             0   \n",
       "1    Exec-managerial  Not-in-family               White  Female             0   \n",
       "2                  ?      Unmarried  Asian-Pac-Islander  Female             0   \n",
       "3  Machine-op-inspct      Unmarried               White  Female             0   \n",
       "4     Prof-specialty      Own-child               White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the CSV file\n",
    "adult_df_categorical = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "# Randomly change some values in the 'education' column\n",
    "def add_categorical_noise_inplace(column, noise_level=0.1):\n",
    "    unique_values = column.unique()\n",
    "    for i in range(len(column)):\n",
    "        if random.random() < noise_level:  # Apply noise with the given probability\n",
    "            column.iat[i] = random.choice(unique_values)\n",
    "\n",
    "# Apply noise to the 'education' column\n",
    "add_categorical_noise_inplace(adult_df_categorical['education'], noise_level=0.2)\n",
    "\n",
    "# Apply noise to the 'marital_status' column\n",
    "add_categorical_noise_inplace(adult_df_categorical['marital.status'], noise_level=0.2)\n",
    "\n",
    "# Apply noise to the 'race' column\n",
    "add_categorical_noise_inplace(adult_df_categorical['race'], noise_level=0.2)\n",
    "\n",
    "adult_df_categorical.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ML Algorithms - Gaussian Noise Categorical: Normal Noise, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 13)\n",
      "Number of observation after removing: (32518, 13)\n",
      "Number of observation before removing: (32518, 13)\n",
      "Number of observation after removing: (32359, 13)\n",
      "Number of observations in final dataset: (32157, 98)\n"
     ]
    }
   ],
   "source": [
    "# Delete columns\n",
    "del_cols_categorical = ['relationship','education.num']\n",
    "adult_df_categorical.drop(labels = del_cols,axis = 1,inplace = True)\n",
    "\n",
    "hrs_per_week_categorical = adult_df_categorical[adult_df_categorical['hours.per.week'] == 99]\n",
    "\n",
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df_categorical.shape)\n",
    "index_age_categorical = adult_df_categorical[adult_df_categorical['age'] == 90].index\n",
    "adult_df_categorical.drop(labels = index_age_categorical,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical.shape)\n",
    "\n",
    "print(\"Number of observation before removing:\",adult_df_categorical.shape)\n",
    "index_gain_categorical = adult_df_categorical[adult_df_categorical['capital.gain'] == 99999].index\n",
    "adult_df_categorical.drop(labels = index_gain_categorical,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical.shape)\n",
    "\n",
    "num_col_new_categorical = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new_categorical = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler_categorical = MinMaxScaler()\n",
    "pd.DataFrame(scaler_categorical.fit_transform(adult_df_categorical[num_col_new_categorical]),columns = num_col_new_categorical).head(3)\n",
    "\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline_categorical = Pipeline([('selector',DataFrameSelector(num_col_new)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n",
    "num_df_categorical = pipeline_categorical.fit_transform(adult_df_categorical)\n",
    "num_df_categorical.shape\n",
    "\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols_categorical = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']\n",
    "\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols_categorical\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df_categorical = pd.get_dummies(X)\n",
    "        df_new_categorical = df_categorical[df_categorical.columns.difference(cols)]\n",
    "#difference returns the original columns, with the columns passed as argument removed.\n",
    "        return df_new_categorical\n",
    "\n",
    "pipeline_cat_categorical=Pipeline([('selector',DataFrameSelector(cat_col_new)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df_categorical = pipeline_cat_categorical.fit_transform(adult_df_categorical)\n",
    "cat_df_categorical.shape\n",
    "\n",
    "cat_df_categorical['id'] = pd.Series(range(cat_df_categorical.shape[0]))\n",
    "num_df_categorical['id'] = pd.Series(range(num_df_categorical.shape[0]))\n",
    "\n",
    "final_df_categorical = pd.merge(cat_df_categorical,num_df_categorical,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df_categorical.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the Model - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 83.5572%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 968  921]\n",
      " [ 401 5750]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 83.5572%\n",
      "Recall Score: 93.4807%\n",
      "Specificity Score: 51.2440%\n",
      "False Positive Rate: 48.7560%\n",
      "Precision Score: 86.1940%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.51      0.59      1889\n",
      "        True       0.86      0.93      0.90      6151\n",
      "\n",
      "    accuracy                           0.84      8040\n",
      "   macro avg       0.78      0.72      0.75      8040\n",
      "weighted avg       0.83      0.84      0.83      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 78.5323%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1022  867]\n",
      " [ 859 5292]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 78.5323%\n",
      "Recall Score: 86.0348%\n",
      "Specificity Score: 54.1027%\n",
      "False Positive Rate: 45.8973%\n",
      "Precision Score: 85.9230%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.54      0.54      1889\n",
      "        True       0.86      0.86      0.86      6151\n",
      "\n",
      "    accuracy                           0.79      8040\n",
      "   macro avg       0.70      0.70      0.70      8040\n",
      "weighted avg       0.79      0.79      0.79      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 80.0000%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 822 1067]\n",
      " [ 541 5610]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 80.0000%\n",
      "Recall Score: 91.2047%\n",
      "Specificity Score: 43.5151%\n",
      "False Positive Rate: 56.4849%\n",
      "Precision Score: 84.0198%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.44      0.51      1889\n",
      "        True       0.84      0.91      0.87      6151\n",
      "\n",
      "    accuracy                           0.80      8040\n",
      "   macro avg       0.72      0.67      0.69      8040\n",
      "weighted avg       0.78      0.80      0.79      8040\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 30.5846%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1856   33]\n",
      " [5548  603]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 30.5846%\n",
      "Recall Score: 9.8033%\n",
      "Specificity Score: 98.2530%\n",
      "False Positive Rate: 1.7470%\n",
      "Precision Score: 94.8113%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.25      0.98      0.40      1889\n",
      "        True       0.95      0.10      0.18      6151\n",
      "\n",
      "    accuracy                           0.31      8040\n",
      "   macro avg       0.60      0.54      0.29      8040\n",
      "weighted avg       0.78      0.31      0.23      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/2810526459.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "y = final_df_categorical['income_<=50K']\n",
    "final_df_categorical.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidentification for Categorical (0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-identification Rate: 19.39%\n",
      "\n",
      "Distance Statistics:\n",
      "Mean Distance: 0.3300\n",
      "Median Distance: 0.2308\n",
      "Min Distance: 0.0285\n",
      "Max Distance: 2.2078\n",
      "\n",
      "Correct Matches: 6313\n",
      "Total Records: 32561\n",
      "Re-identification Rate: 19.39%\n",
      "\n",
      "Percentage of changed values in education: 18.37%\n",
      "\n",
      "Percentage of changed values in marital.status: 17.16%\n",
      "\n",
      "Percentage of changed values in race: 16.26%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "adult_df_original = pd.read_csv('adult.csv')\n",
    "adult_df_categorical_noise = adult_df_original.copy()\n",
    "\n",
    "# function to add categorical noise\n",
    "def add_categorical_noise_inplace(column, noise_level=0.1):\n",
    "    unique_values = column.unique()\n",
    "    for i in range(len(column)):\n",
    "        if np.random.random() < noise_level:  # Apply noise with the given probability\n",
    "            column.iat[i] = np.random.choice(unique_values)\n",
    "\n",
    "# apply noise to categorical columns\n",
    "categorical_columns = ['education', 'marital.status', 'race']\n",
    "for col in categorical_columns:\n",
    "    add_categorical_noise_inplace(adult_df_categorical_noise[col], noise_level=0.2)\n",
    "\n",
    "def encode_categorical(df, columns):\n",
    "    le = LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# encode categorical variables for both original and noisy datasets\n",
    "adult_df_original_encoded = encode_categorical(adult_df_original.copy(), categorical_columns)\n",
    "adult_df_categorical_noise_encoded = encode_categorical(adult_df_categorical_noise.copy(), categorical_columns)\n",
    "\n",
    "# columns to compare (including encoded categorical columns)\n",
    "cols_to_compare = categorical_columns + ['age', 'capital.gain', 'hours.per.week']\n",
    "\n",
    "def normalize(df, cols):\n",
    "    return (df[cols] - df[cols].mean()) / df[cols].std()\n",
    "\n",
    "original_normalized = normalize(adult_df_original_encoded, cols_to_compare)\n",
    "categorical_noise_normalized = normalize(adult_df_categorical_noise_encoded, cols_to_compare)\n",
    "\n",
    "indices, distances = pairwise_distances_argmin_min(categorical_noise_normalized, original_normalized)\n",
    "\n",
    "correct_matches = sum(np.arange(len(adult_df_original)) == indices)\n",
    "reidentification_rate = correct_matches / len(adult_df_original)\n",
    "\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original_Index': np.arange(len(adult_df_original)),\n",
    "    'Matched_Index': indices,\n",
    "    'Distance': distances,\n",
    "    'Correctly_Matched': np.arange(len(adult_df_original)) == indices\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\nDistance Statistics:\")\n",
    "print(f\"Mean Distance: {np.mean(distances):.4f}\")\n",
    "print(f\"Median Distance: {np.median(distances):.4f}\")\n",
    "print(f\"Min Distance: {np.min(distances):.4f}\")\n",
    "print(f\"Max Distance: {np.max(distances):.4f}\")\n",
    "\n",
    "print(\"\\nCorrect Matches:\", correct_matches)\n",
    "print(\"Total Records:\", len(adult_df_original))\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "# Calculate and print the percentage of changed values for each categorical column\n",
    "for col in categorical_columns:\n",
    "    changed_values = sum(adult_df_original[col] != adult_df_categorical_noise[col])\n",
    "    change_percentage = (changed_values / len(adult_df_original)) * 100\n",
    "    print(f\"\\nPercentage of changed values in {col}: {change_percentage:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data - Gaussian Noise Categorical: Double Noise, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>11th</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870          11th              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10  Never-married   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship                race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  Asian-Pac-Islander  Female             0   \n",
       "1    Exec-managerial  Not-in-family  Asian-Pac-Islander  Female             0   \n",
       "2                  ?      Unmarried               Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried               White  Female             0   \n",
       "4     Prof-specialty      Own-child               White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "adult_df_categorical_double = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "# Randomly change some values in the 'education' column\n",
    "def add_categorical_noise_inplace(column, noise_level=0.1):\n",
    "    unique_values = column.unique()\n",
    "    for i in range(len(column)):\n",
    "        if random.random() < noise_level:  # Apply noise with the given probability\n",
    "            column.iat[i] = random.choice(unique_values)\n",
    "\n",
    "# Apply noise to the 'education' column\n",
    "add_categorical_noise_inplace(adult_df_categorical_double['education'], noise_level=0.4)\n",
    "\n",
    "# Apply noise to the 'marital_status' column\n",
    "add_categorical_noise_inplace(adult_df_categorical_double['marital.status'], noise_level=0.4)\n",
    "\n",
    "# Apply noise to the 'race' column\n",
    "add_categorical_noise_inplace(adult_df_categorical_double['race'], noise_level=0.4)\n",
    "\n",
    "adult_df_categorical_double.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ML Algorithms - Gaussian Noise Categorical: Double Noise, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 15)\n",
      "Number of observation after removing: (32518, 15)\n",
      "Number of observation before removing: (32518, 15)\n",
      "Number of observation after removing: (32359, 15)\n",
      "Number of observations in final dataset: (32157, 98)\n"
     ]
    }
   ],
   "source": [
    "hrs_per_week_categorical_double = adult_df_categorical_double[adult_df_categorical_double['hours.per.week'] == 99]\n",
    "\n",
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df_categorical_double.shape)\n",
    "index_age_categorical_double = adult_df_categorical_double[adult_df_categorical_double['age'] == 90].index\n",
    "adult_df_categorical_double.drop(labels = index_age_categorical_double,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical_double.shape)\n",
    "\n",
    "print(\"Number of observation before removing:\",adult_df_categorical_double.shape)\n",
    "index_gain_categorical_double = adult_df_categorical_double[adult_df_categorical_double['capital.gain'] == 99999].index\n",
    "adult_df_categorical_double.drop(labels = index_gain_categorical_double,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical_double.shape)\n",
    "\n",
    "num_col_new_categorical_double = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new_categorical_double = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler_categorical_double = MinMaxScaler()\n",
    "pd.DataFrame(scaler_categorical_double.fit_transform(adult_df_categorical_double[num_col_new_categorical_double]),columns = num_col_new_categorical_double).head(3)\n",
    "\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline_categorical_double = Pipeline([('selector',DataFrameSelector(num_col_new)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n",
    "num_df_categorical_double = pipeline_categorical_double.fit_transform(adult_df_categorical_double)\n",
    "num_df_categorical_double.shape\n",
    "\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols_categorical_double = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']\n",
    "\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols_categorical_double\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df_categorical_double = pd.get_dummies(X)\n",
    "        df_new_categorical_double = df_categorical_double[df_categorical_double.columns.difference(cols)]\n",
    "#difference returns the original columns, with the columns passed as argument removed.\n",
    "        return df_new_categorical_double\n",
    "\n",
    "pipeline_cat_categorical_double=Pipeline([('selector',DataFrameSelector(cat_col_new)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df_categorical_double = pipeline_cat_categorical_double.fit_transform(adult_df_categorical_double)\n",
    "cat_df_categorical_double.shape\n",
    "\n",
    "cat_df_categorical_double['id'] = pd.Series(range(cat_df_categorical_double.shape[0]))\n",
    "num_df_categorical_double['id'] = pd.Series(range(num_df_categorical_double.shape[0]))\n",
    "\n",
    "final_df_categorical_double = pd.merge(cat_df_categorical_double,num_df_categorical_double,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df_categorical_double.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the Model - Gaussian Noise Categorical: Double Noise, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 82.2264%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 836 1053]\n",
      " [ 376 5775]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 82.2264%\n",
      "Recall Score: 93.8872%\n",
      "Specificity Score: 44.2562%\n",
      "False Positive Rate: 55.7438%\n",
      "Precision Score: 84.5782%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.44      0.54      1889\n",
      "        True       0.85      0.94      0.89      6151\n",
      "\n",
      "    accuracy                           0.82      8040\n",
      "   macro avg       0.77      0.69      0.71      8040\n",
      "weighted avg       0.81      0.82      0.81      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/650239692.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 76.3557%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 974  915]\n",
      " [ 986 5165]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 76.3557%\n",
      "Recall Score: 83.9701%\n",
      "Specificity Score: 51.5617%\n",
      "False Positive Rate: 48.4383%\n",
      "Precision Score: 84.9507%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.52      0.51      1889\n",
      "        True       0.85      0.84      0.84      6151\n",
      "\n",
      "    accuracy                           0.76      8040\n",
      "   macro avg       0.67      0.68      0.68      8040\n",
      "weighted avg       0.77      0.76      0.77      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/650239692.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 78.2960%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 661 1228]\n",
      " [ 517 5634]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 78.2960%\n",
      "Recall Score: 91.5949%\n",
      "Specificity Score: 34.9921%\n",
      "False Positive Rate: 65.0079%\n",
      "Precision Score: 82.1043%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.35      0.43      1889\n",
      "        True       0.82      0.92      0.87      6151\n",
      "\n",
      "    accuracy                           0.78      8040\n",
      "   macro avg       0.69      0.63      0.65      8040\n",
      "weighted avg       0.76      0.78      0.76      8040\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 30.0995%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1853   36]\n",
      " [5584  567]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 30.0995%\n",
      "Recall Score: 9.2180%\n",
      "Specificity Score: 98.0942%\n",
      "False Positive Rate: 1.9058%\n",
      "Precision Score: 94.0299%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.25      0.98      0.40      1889\n",
      "        True       0.94      0.09      0.17      6151\n",
      "\n",
      "    accuracy                           0.30      8040\n",
      "   macro avg       0.59      0.54      0.28      8040\n",
      "weighted avg       0.78      0.30      0.22      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/650239692.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/650239692.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "y = final_df_categorical_double['income_<=50K']\n",
    "final_df_categorical_double.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df_categorical_double\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidentification on Gaussian Noise Categorical: Double Noise, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-identification Rate: 6.32%\n",
      "\n",
      "Distance Statistics:\n",
      "Mean Distance: 0.4989\n",
      "Median Distance: 0.4352\n",
      "Min Distance: 0.0854\n",
      "Max Distance: 3.4044\n",
      "\n",
      "Correct Matches: 2057\n",
      "Total Records: 32561\n",
      "Re-identification Rate: 6.32%\n",
      "\n",
      "Percentage of changed values in education: 37.27%\n",
      "\n",
      "Percentage of changed values in marital.status: 34.62%\n",
      "\n",
      "Percentage of changed values in race: 32.60%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "adult_df_original = pd.read_csv('adult.csv')\n",
    "adult_df_categorical_noise = adult_df_original.copy()\n",
    "\n",
    "# function to add categorical noise\n",
    "def add_categorical_noise_inplace(column, noise_level=0.1):\n",
    "    unique_values = column.unique()\n",
    "    for i in range(len(column)):\n",
    "        if np.random.random() < noise_level:  # Apply noise with the given probability\n",
    "            column.iat[i] = np.random.choice(unique_values)\n",
    "\n",
    "# apply noise to categorical columns\n",
    "categorical_columns = ['education', 'marital.status', 'race']\n",
    "for col in categorical_columns:\n",
    "    add_categorical_noise_inplace(adult_df_categorical_noise[col], noise_level=0.4)\n",
    "\n",
    "def encode_categorical(df, columns):\n",
    "    le = LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# encode categorical variables for both original and noisy datasets\n",
    "adult_df_original_encoded = encode_categorical(adult_df_original.copy(), categorical_columns)\n",
    "adult_df_categorical_noise_encoded = encode_categorical(adult_df_categorical_noise.copy(), categorical_columns)\n",
    "\n",
    "# columns to compare (including encoded categorical columns)\n",
    "cols_to_compare = categorical_columns + ['age', 'capital.gain', 'hours.per.week']\n",
    "\n",
    "def normalize(df, cols):\n",
    "    return (df[cols] - df[cols].mean()) / df[cols].std()\n",
    "\n",
    "original_normalized = normalize(adult_df_original_encoded, cols_to_compare)\n",
    "categorical_noise_normalized = normalize(adult_df_categorical_noise_encoded, cols_to_compare)\n",
    "\n",
    "indices, distances = pairwise_distances_argmin_min(categorical_noise_normalized, original_normalized)\n",
    "\n",
    "correct_matches = sum(np.arange(len(adult_df_original)) == indices)\n",
    "reidentification_rate = correct_matches / len(adult_df_original)\n",
    "\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original_Index': np.arange(len(adult_df_original)),\n",
    "    'Matched_Index': indices,\n",
    "    'Distance': distances,\n",
    "    'Correctly_Matched': np.arange(len(adult_df_original)) == indices\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\nDistance Statistics:\")\n",
    "print(f\"Mean Distance: {np.mean(distances):.4f}\")\n",
    "print(f\"Median Distance: {np.median(distances):.4f}\")\n",
    "print(f\"Min Distance: {np.min(distances):.4f}\")\n",
    "print(f\"Max Distance: {np.max(distances):.4f}\")\n",
    "\n",
    "print(\"\\nCorrect Matches:\", correct_matches)\n",
    "print(\"Total Records:\", len(adult_df_original))\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "# Calculate and print the percentage of changed values for each categorical column\n",
    "for col in categorical_columns:\n",
    "    changed_values = sum(adult_df_original[col] != adult_df_categorical_noise[col])\n",
    "    change_percentage = (changed_values / len(adult_df_original)) * 100\n",
    "    print(f\"\\nPercentage of changed values in {col}: {change_percentage:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data - Gaussian Noise Categorical: Triple Noise, 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>11th</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>12th</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0   90         ?   77053  Some-college              9             Widowed   \n",
       "1   82   Private  132870          11th              9           Separated   \n",
       "2   66         ?  186061          12th             10       Never-married   \n",
       "3   54   Private  140359       7th-8th              4  Married-civ-spouse   \n",
       "4   41   Private  264663     Assoc-voc             10            Divorced   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  Black  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  Black  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the CSV file\n",
    "adult_df_categorical_triple = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "# Randomly change some values in the 'education' column\n",
    "def add_categorical_noise_inplace(column, noise_level=0.1):\n",
    "    unique_values = column.unique()\n",
    "    for i in range(len(column)):\n",
    "        if random.random() < noise_level:  # Apply noise with the given probability\n",
    "            column.iat[i] = random.choice(unique_values)\n",
    "\n",
    "# Apply noise to the 'education' column\n",
    "add_categorical_noise_inplace(adult_df_categorical_triple['education'], noise_level=0.6)\n",
    "\n",
    "# Apply noise to the 'marital_status' column\n",
    "add_categorical_noise_inplace(adult_df_categorical_triple['marital.status'], noise_level=0.6)\n",
    "\n",
    "# Apply noise to the 'race' column\n",
    "add_categorical_noise_inplace(adult_df_categorical_triple['race'], noise_level=0.6)\n",
    "\n",
    "adult_df_categorical_triple.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ML Algorithms - Gaussian Noise Categorical: Triple Noise, 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation before removing: (32561, 15)\n",
      "Number of observation after removing: (32518, 15)\n",
      "Number of observation before removing: (32518, 15)\n",
      "Number of observation after removing: (32359, 15)\n",
      "Number of observations in final dataset: (32157, 98)\n"
     ]
    }
   ],
   "source": [
    "hrs_per_week_categorical_triple = adult_df_categorical_triple[adult_df_categorical_triple['hours.per.week'] == 99]\n",
    "\n",
    "# drop rows with age 90\n",
    "print(\"Number of observation before removing:\",adult_df_categorical_triple.shape)\n",
    "index_age_categorical_triple = adult_df_categorical_triple[adult_df_categorical_triple['age'] == 90].index\n",
    "adult_df_categorical_triple.drop(labels = index_age_categorical_triple,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical_triple.shape)\n",
    "\n",
    "print(\"Number of observation before removing:\",adult_df_categorical_triple.shape)\n",
    "index_gain_categorical_triple = adult_df_categorical_triple[adult_df_categorical_triple['capital.gain'] == 99999].index\n",
    "adult_df_categorical_triple.drop(labels = index_gain_categorical_triple,axis = 0,inplace =True)\n",
    "print(\"Number of observation after removing:\",adult_df_categorical_triple.shape)\n",
    "\n",
    "num_col_new_categorical_triple = ['age','capital.gain', 'capital.loss',\n",
    "       'hours.per.week','fnlwgt']\n",
    "cat_col_new_categorical_triple = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler_categorical_triple = MinMaxScaler()\n",
    "pd.DataFrame(scaler_categorical_triple.fit_transform(adult_df_categorical_triple[num_col_new_categorical_triple]),columns = num_col_new_categorical_triple).head(3)\n",
    "\n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "\n",
    "class num_trans(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df = pd.DataFrame(X)\n",
    "        df.columns = num_col_new\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "pipeline_categorical_triple = Pipeline([('selector',DataFrameSelector(num_col_new)),\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                    ('transform',num_trans())])\n",
    "\n",
    "num_df_categorical_triple = pipeline_categorical_triple.fit_transform(adult_df_categorical_triple)\n",
    "num_df_categorical_triple.shape\n",
    "\n",
    "# columns which I don't need after creating dummy variables dataframe\n",
    "cols_categorical_triple = ['workclass_Govt_employess','education_Some-college',\n",
    "        'marital.status_Never-married','occupation_Other-service',\n",
    "        'race_Black','sex_Male','income_>50K']\n",
    "\n",
    "class dummies(TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols_categorical_triple\n",
    "\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        df_categorical_triple = pd.get_dummies(X)\n",
    "        df_new_categorical_triple = df_categorical_triple[df_categorical_triple.columns.difference(cols)]\n",
    "#difference returns the original columns, with the columns passed as argument removed.\n",
    "        return df_new_categorical_triple\n",
    "\n",
    "pipeline_cat_categorical_triple=Pipeline([('selector',DataFrameSelector(cat_col_new)),\n",
    "                      ('dummies',dummies(cols))])\n",
    "cat_df_categorical_triple = pipeline_cat_categorical_triple.fit_transform(adult_df_categorical_triple)\n",
    "cat_df_categorical_triple.shape\n",
    "\n",
    "cat_df_categorical_triple['id'] = pd.Series(range(cat_df_categorical_triple.shape[0]))\n",
    "num_df_categorical_triple['id'] = pd.Series(range(num_df_categorical_triple.shape[0]))\n",
    "\n",
    "final_df_categorical_triple = pd.merge(cat_df_categorical_triple,num_df_categorical_triple,how = 'inner', on = 'id')\n",
    "print(f\"Number of observations in final dataset: {final_df_categorical_triple.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Fine Tuning on the Model - Gaussian Noise Categorical: Triple Noise, 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------LogisticRegression---------------------------------------------------\n",
      "Accuracy Score for LogisticRegression: 81.7289%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 743 1146]\n",
      " [ 323 5828]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 81.7289%\n",
      "Recall Score: 94.7488%\n",
      "Specificity Score: 39.3330%\n",
      "False Positive Rate: 60.6670%\n",
      "Precision Score: 83.5675%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.39      0.50      1889\n",
      "        True       0.84      0.95      0.89      6151\n",
      "\n",
      "    accuracy                           0.82      8040\n",
      "   macro avg       0.77      0.67      0.70      8040\n",
      "weighted avg       0.80      0.82      0.80      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/178676694.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------DecisionTree---------------------------------------------------\n",
      "Accuracy Score for DecisionTree: 75.2861%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 967  922]\n",
      " [1065 5086]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 75.2861%\n",
      "Recall Score: 82.6857%\n",
      "Specificity Score: 51.1911%\n",
      "False Positive Rate: 48.8089%\n",
      "Precision Score: 84.6538%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.48      0.51      0.49      1889\n",
      "        True       0.85      0.83      0.84      6151\n",
      "\n",
      "    accuracy                           0.75      8040\n",
      "   macro avg       0.66      0.67      0.66      8040\n",
      "weighted avg       0.76      0.75      0.76      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/178676694.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------KNN---------------------------------------------------\n",
      "Accuracy Score for KNN: 77.8980%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[ 624 1265]\n",
      " [ 512 5639]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 77.8980%\n",
      "Recall Score: 91.6762%\n",
      "Specificity Score: 33.0334%\n",
      "False Positive Rate: 66.9666%\n",
      "Precision Score: 81.6773%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      0.33      0.41      1889\n",
      "        True       0.82      0.92      0.86      6151\n",
      "\n",
      "    accuracy                           0.78      8040\n",
      "   macro avg       0.68      0.62      0.64      8040\n",
      "weighted avg       0.75      0.78      0.76      8040\n",
      "\n",
      "--------------------------------------------Naive---------------------------------------------------\n",
      "Accuracy Score for Naive: 29.6144%\n",
      "Null Accuracy: 76.5050%\n",
      "Confusion Matrix\n",
      "[[1853   36]\n",
      " [5623  528]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Accuracy Score: 29.6144%\n",
      "Recall Score: 8.5840%\n",
      "Specificity Score: 98.0942%\n",
      "False Positive Rate: 1.9058%\n",
      "Precision Score: 93.6170%\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.25      0.98      0.40      1889\n",
      "        True       0.94      0.09      0.16      6151\n",
      "\n",
      "    accuracy                           0.30      8040\n",
      "   macro avg       0.59      0.53      0.28      8040\n",
      "weighted avg       0.77      0.30      0.21      8040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/178676694.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
      "/var/folders/z8/s91hq90s63g6lxrs6j4r1sx40000gn/T/ipykernel_54501/178676694.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  null_accuracy = y_test.value_counts()[0]/len(y_test)\n"
     ]
    }
   ],
   "source": [
    "y = final_df_categorical_triple['income_<=50K']\n",
    "final_df_categorical_triple.drop(labels = ['id','income_<=50K'],axis = 1,inplace = True)\n",
    "X = final_df_categorical_triple\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.25,random_state = 42)\n",
    "\n",
    "#Instantiate the classifiers\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_knn =  KNeighborsClassifier()\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "classifiers = ['LogisticRegression', 'DecisionTree', 'KNN', 'SVC', 'Naive']\n",
    "\n",
    "models = {clf_logreg:'LogisticRegression',\n",
    "          clf_tree:'DecisionTree',\n",
    "          clf_knn: 'KNN',\n",
    "          clf_gnb: 'Naive'}\n",
    "\n",
    "# train function fits the model and returns accuracy score\n",
    "def train(algo,name,X_train,y_train,X_test,y_test):\n",
    "    algo.fit(X_train,y_train)\n",
    "    y_pred = algo.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "    print(f\"--------------------------------------------{name}---------------------------------------------------\")\n",
    "    print(f\"Accuracy Score for {name}: {score*100:.4f}%\")\n",
    "    return y_test,y_pred,score\n",
    "\n",
    "# acc_res function calculates confusion matrix\n",
    "def acc_res(y_test,y_pred):\n",
    "    null_accuracy = y_test.value_counts()[0]/len(y_test)\n",
    "    print(f\"Null Accuracy: {null_accuracy*100:.4f}%\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(matrix)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    TN = matrix[0,0]\n",
    "    FP = matrix[0,1]\n",
    "    FN = matrix[1,0]\n",
    "    TP = matrix[1,1]\n",
    "    accuracy_score=(TN+TP) / float(TP+TN+FP+FN)\n",
    "    recall_score = (TP)/ float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    FPR = FP / float(FP+TN)\n",
    "    precision_score = TP / float(TP+FP)\n",
    "    print(f\"Accuracy Score: {accuracy_score*100:.4f}%\")\n",
    "    print(f\"Recall Score: {recall_score*100:.4f}%\")\n",
    "    print(f\"Specificity Score: {specificity*100:.4f}%\")\n",
    "    print(f\"False Positive Rate: {FPR*100:.4f}%\")\n",
    "    print(f\"Precision Score: {precision_score*100:.4f}%\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "def main(models):\n",
    "    accuracy_scores = []\n",
    "    for algo,name in models.items():\n",
    "        y_test_train,y_pred,acc_score = train(algo,name,X_train,y_train,X_test,y_test)\n",
    "        acc_res(y_test_train,y_pred)\n",
    "        accuracy_scores.append(acc_score)\n",
    "    return accuracy_scores\n",
    "\n",
    "accuracy_scores = main(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidentification on Gaussian Noise Categorical: Triple Noise, 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-identification Rate: 3.06%\n",
      "\n",
      "Distance Statistics:\n",
      "Mean Distance: 0.5998\n",
      "Median Distance: 0.5868\n",
      "Min Distance: 0.1640\n",
      "Max Distance: 2.2477\n",
      "\n",
      "Correct Matches: 997\n",
      "Total Records: 32561\n",
      "Re-identification Rate: 3.06%\n",
      "\n",
      "Percentage of changed values in education: 56.51%\n",
      "\n",
      "Percentage of changed values in marital.status: 51.36%\n",
      "\n",
      "Percentage of changed values in race: 48.28%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "adult_df_original = pd.read_csv('adult.csv')\n",
    "adult_df_categorical_noise = adult_df_original.copy()\n",
    "\n",
    "# function to add categorical noise\n",
    "def add_categorical_noise_inplace(column, noise_level=0.1):\n",
    "    unique_values = column.unique()\n",
    "    for i in range(len(column)):\n",
    "        if np.random.random() < noise_level:  # Apply noise with the given probability\n",
    "            column.iat[i] = np.random.choice(unique_values)\n",
    "\n",
    "# apply noise to categorical columns\n",
    "categorical_columns = ['education', 'marital.status', 'race']\n",
    "for col in categorical_columns:\n",
    "    add_categorical_noise_inplace(adult_df_categorical_noise[col], noise_level=0.6)\n",
    "\n",
    "def encode_categorical(df, columns):\n",
    "    le = LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# encode categorical variables for both original and noisy datasets\n",
    "adult_df_original_encoded = encode_categorical(adult_df_original.copy(), categorical_columns)\n",
    "adult_df_categorical_noise_encoded = encode_categorical(adult_df_categorical_noise.copy(), categorical_columns)\n",
    "\n",
    "# columns to compare (including encoded categorical columns)\n",
    "cols_to_compare = categorical_columns + ['age', 'capital.gain', 'hours.per.week']\n",
    "\n",
    "def normalize(df, cols):\n",
    "    return (df[cols] - df[cols].mean()) / df[cols].std()\n",
    "\n",
    "original_normalized = normalize(adult_df_original_encoded, cols_to_compare)\n",
    "categorical_noise_normalized = normalize(adult_df_categorical_noise_encoded, cols_to_compare)\n",
    "\n",
    "indices, distances = pairwise_distances_argmin_min(categorical_noise_normalized, original_normalized)\n",
    "\n",
    "correct_matches = sum(np.arange(len(adult_df_original)) == indices)\n",
    "reidentification_rate = correct_matches / len(adult_df_original)\n",
    "\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original_Index': np.arange(len(adult_df_original)),\n",
    "    'Matched_Index': indices,\n",
    "    'Distance': distances,\n",
    "    'Correctly_Matched': np.arange(len(adult_df_original)) == indices\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\nDistance Statistics:\")\n",
    "print(f\"Mean Distance: {np.mean(distances):.4f}\")\n",
    "print(f\"Median Distance: {np.median(distances):.4f}\")\n",
    "print(f\"Min Distance: {np.min(distances):.4f}\")\n",
    "print(f\"Max Distance: {np.max(distances):.4f}\")\n",
    "\n",
    "print(\"\\nCorrect Matches:\", correct_matches)\n",
    "print(\"Total Records:\", len(adult_df_original))\n",
    "print(f\"Re-identification Rate: {reidentification_rate * 100:.2f}%\")\n",
    "\n",
    "# Calculate and print the percentage of changed values for each categorical column\n",
    "for col in categorical_columns:\n",
    "    changed_values = sum(adult_df_original[col] != adult_df_categorical_noise[col])\n",
    "    change_percentage = (changed_values / len(adult_df_original)) * 100\n",
    "    print(f\"\\nPercentage of changed values in {col}: {change_percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
